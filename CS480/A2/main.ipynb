{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation Library\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Optimization module in scipy\n",
    "from scipy import optimize\n",
    "\n",
    "# data url\n",
    "github_url = 'https://raw.githubusercontent.com/RohanK99/machine-learning/master/CS480/A1/knn-dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training data\n",
    "training_data = []\n",
    "training_labels = []\n",
    "for i in range(10):\n",
    "    # training data\n",
    "    url = github_url + 'trainData{}.csv'.format(i+1)\n",
    "    data = pd.read_csv(url, header=None)\n",
    "    training_data.append(data)\n",
    "    # training labels\n",
    "    url = github_url + 'trainLabels{}.csv'.format(i+1)\n",
    "    data = pd.read_csv(url, header=None)\n",
    "    training_labels.append(data)\n",
    "\n",
    "# concatenate data into 1 large data set and convert to numpy\n",
    "X = (pd.concat(training_data)).to_numpy()\n",
    "X = np.c_[np.ones(X.shape[0]), X] # add column of ones\n",
    "y = ((pd.concat(training_labels)).to_numpy())[:,0] # first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test data\n",
    "data_url = github_url + 'testData.csv'\n",
    "label_url = github_url + 'testLabels.csv'\n",
    "data = pd.read_csv(data_url, header=None)\n",
    "t_X = data.to_numpy()\n",
    "t_X = np.c_[np.ones(t_X.shape[0]), t_X] # add column of ones\n",
    "labels = pd.read_csv(label_url, header=None)\n",
    "t_y = labels.to_numpy()[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "### a) \n",
    "Mixture of Gaussians: let $\\pi = P(y = C_1)$ and $1 - \\pi=P(y = C_2)$. Let $P(x|C_1)=N(x|\\mu_1, \\Sigma)$ and $P(x|C_2) = N(x|\\mu_2, \\Sigma)$. Learn the parameters $\\pi$, $\\mu_1$, $\\mu_2$ and $\\Sigma$ by likelihood maximization. Use Bayes theorem to compute the probability of each class given an input $x: P(C_j|x) = k P(C_j) P(x|C_j)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can express the Likelihood of our training set as $L(X,y) = P(X,y|\\pi,\\mu_1,\\mu_2,\\Sigma)$. We want to maximize the likelihood in order to use Bayes inference.\n",
    "$$\n",
    "\\begin{align*}\n",
    "L(X,y) &= \\prod_{n}{[\\pi|\\mu_1, \\Sigma]^{y_n}[(1-\\pi)|N(x_n|\\mu_2,\\Sigma)]^{1-y_n}}\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "Taking the log we can turn this into an optimization problem of finding\n",
    "$$\n",
    "\\begin{align*}\n",
    "&= argmax_{\\pi, \\mu_1, \\mu_2, \\Sigma} \\sum _{n}{y_n[ln\\pi - \\frac{1}{2}(x_n - \\mu_1)^T \\Sigma^{-1}(x_n-\\mu_1)]+(1-y_n)[ln\\pi - \\frac{1}{2}(x_n - \\mu_2)^T \\Sigma^{-1}(x_n-\\mu_2)]}\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classes\n",
    "c_1 = y == 5\n",
    "c_2 = y == 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to estimate $\\pi$ (probability of class) we can take:\n",
    "$$\n",
    "\\begin{align*}\n",
    "0 &= \\frac{\\partial lnL(X,y)}{\\partial \\pi} \\\\\n",
    "\\pi &= \\frac{\\sum_n{y_n}}{N} \\\\\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "pi is: 0.5\n"
    }
   ],
   "source": [
    "pi = np.count_nonzero(c_1)/y.shape[0]\n",
    "print(\"pi is: \" + str(pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to estimate $\\mu_1$ and $\\mu_2$ (mean of classes) we can take:\n",
    "$$\n",
    "\\begin{align*}\n",
    "0 &= \\frac{\\partial lnL(X,y)}{\\partial \\mu_1} \\\\\n",
    "\\mu_1 &= \\frac{\\sum_n{y_n}{x_n}}{N_1} \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "0 &= \\frac{\\partial lnL(X,y)}{\\partial \\mu_2} \\\\\n",
    "\\mu_2 &= \\frac{\\sum_n{(1-y_n)}{x_n}}{N_2} \\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "mu_1 is: [ 1.     4.846  4.902  8.28   9.858 10.68   9.342  6.198  4.602  4.978\n  5.998 10.498  9.662  8.448  7.66   5.322  4.412  4.438  6.36  10.02\n  6.84   5.6    4.764  4.436  4.366  4.758  6.392 10.126  9.514  7.924\n  6.302  4.532  4.64   4.812  5.274  7.596  7.948  8.518  7.668  5.634\n  4.226  4.612  4.718  4.924  5.762  7.362  8.612  5.764  4.408  4.29\n  5.038  7.032  7.762  8.782  7.908  5.516  4.548  4.456  4.758  8.606\n 10.226  8.702  6.198  5.002  4.944]\nmu_2 is: [ 1.     5.158  4.954  5.654  9.55   8.618  5.482  5.478  4.896  4.782\n  4.75   8.194 10.272  7.03   5.272  4.864  4.736  4.864  5.058  9.814\n  8.438  4.92   5.068  4.762  4.882  4.686  5.76  10.572  8.02   6.306\n  5.47   5.154  4.664  4.988  6.278 10.67   9.814  9.532  8.804  5.84\n  4.588  4.832  5.732 10.402  9.132  7.756  9.324  8.338  4.732  4.704\n  5.334  9.224  9.968  7.304  9.668  8.934  4.968  4.932  5.002  5.84\n  9.202 10.99   9.72   6.41   5.186]\n"
    }
   ],
   "source": [
    "mu_1 = np.mean(X[c_1], axis=0)\n",
    "mu_2 = np.mean(X[c_2], axis=0)\n",
    "print(\"mu_1 is: \" + str(mu_1))\n",
    "print(\"mu_2 is: \" + str(mu_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to estimate $\\Sigma$ (covariance matrix) we can take:\n",
    "$$\n",
    "\\begin{align*}\n",
    "0 &= \\frac{\\partial lnL(X,y)}{\\partial \\Sigma} \\\\\n",
    "\\Sigma &= \\frac{N_1}{N}S_1 + \\frac{N_2}{N}S_2\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "where $S_k$ are the empirival covariance matrices of the class k\n",
    "$$\n",
    "\\begin{align*}\n",
    "S_1 &= \\frac{1}{N_1}\\sum _{n\\in C_1}{(x_n-\\mu_1)(x_n-\\mu_1)^T}\\\\\n",
    "S_2 &= \\frac{1}{N_1}\\sum _{n\\in C_2}{(x_n-\\mu_2)(x_n-\\mu_2)^T}\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sigma is: \n[[ 0.          0.          0.         ...  0.          0.\n   0.        ]\n [ 0.         40.14995992 22.0321523  ... 23.16269138 24.42160721\n  26.52504409]\n [ 0.         22.0321523  39.90194389 ... 27.27681563 26.486501\n  26.6588517 ]\n ...\n [ 0.         23.16269138 27.27681563 ... 44.08637074 27.76873948\n  23.90038477]\n [ 0.         24.42160721 26.486501   ... 27.76873948 42.75746293\n  26.02096794]\n [ 0.         26.52504409 26.6588517  ... 23.90038477 26.02096794\n  40.16045491]]\n"
    }
   ],
   "source": [
    "s_1 = np.cov(X[c_1], rowvar=False)\n",
    "s_2 = np.cov(X[c_2], rowvar=False)\n",
    "sigma = X[c_1].shape[0]/y.shape[0] * s_1 + X[c_2].shape[0]/y.shape[0] * s_2\n",
    "print(\"sigma is: \")\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create the bayes inference function to predict the classification. We know that bayes formula is:\n",
    "\n",
    "\\begin{align*}\n",
    "P(C_j|x) &= \\frac{P(C_j) P(x|C_j)}{\\sum_c P(x|C_j)P(C_j)}\\\\\n",
    "&= kP(C_j) P(x|C_j)\n",
    "\\end{align*}\n",
    "\n",
    "Now assuming Gaussian distribution and that the same covariance matrix $\\Sigma$ is used for each class then:\n",
    "\n",
    "\\begin{align*}\n",
    "P(x|C_j) \\propto e^{-\\frac{1}{2}(x-\\mu_k)^T \\Sigma^{-1}(x-\\mu_k)}\n",
    "\\end{align*}\n",
    "\n",
    "Subbing our assumptions to get the posterior distribution we get the logistic sigmoid function.\n",
    "\n",
    "\\begin{align*}\n",
    "P(C_j|x) = \\frac{1}{1 + e^{-(w^Tx+w_o)}}\n",
    "\\end{align*}\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{align*}\n",
    "w &= \\Sigma^{-1}(\\mu_j - \\mu_k)\\\\\n",
    "w_o &= -\\frac{1}{2}\\mu_j^T \\Sigma^{-1}\\mu_j + \\frac{1}{2}\\mu_k^T \\Sigma^{-1}\\mu_k + ln\\frac{\\pi_1}{\\pi_2}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    # convert input to a numpy array\n",
    "    z = np.array(z)\n",
    "    \n",
    "    # compute sigmoid\n",
    "    g = np.zeros(z.shape)\n",
    "    g = 1.0 / (1 + np.exp(-z))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.09843704514833984\n[ 0.         -0.01540531  0.01616244  0.03929692 -0.00456321  0.06182967\n  0.15334141  0.01915415  0.05507069  0.08670551 -0.01681262  0.1203822\n  0.00441396  0.02588328  0.15001922 -0.00107855 -0.04174986  0.07194328\n  0.04522785  0.01061901 -0.02694246 -0.00675116 -0.05810351 -0.04177076\n  0.02758435  0.08169968  0.0226441  -0.02123403  0.01795245  0.09192023\n -0.00836835 -0.07566645 -0.0045614   0.08674114 -0.01242315 -0.06059901\n -0.03379977 -0.02829977 -0.08825168 -0.04110495 -0.03506517 -0.02520544\n  0.00681327 -0.21247372 -0.07226558 -0.00982123  0.03154254  0.02651147\n -0.05090439  0.02273982 -0.09561958 -0.07537277 -0.04687759  0.06141118\n -0.03530406 -0.06769001 -0.00184102 -0.04228458 -0.07332246  0.08705653\n  0.05281176 -0.00978789 -0.05968752 -0.0054356   0.00299748]\n"
    }
   ],
   "source": [
    "sigma_inv = np.linalg.pinv(sigma)\n",
    "w = sigma_inv@(mu_1 - mu_2)\n",
    "w_o = -1/2*mu_1.T@sigma_inv@mu_1 + 1/2*mu_2.T@sigma_inv@mu_2 + np.log(pi/(1-pi))\n",
    "print(w_o)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "accuracy: 89.1%\n"
    }
   ],
   "source": [
    "prediction = sigmoid(t_X@w + w_o) >= 0.5 # prediction 5\n",
    "actual = t_y == 5\n",
    "print(\"accuracy: {:.1f}%\".format(np.sum(prediction == actual)/t_y.shape[0]*100))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}